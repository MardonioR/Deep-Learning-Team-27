{"cells":[{"cell_type":"markdown","id":"41b7905f-a070-4ffe-abfc-67fbcd2adaa9","metadata":{"id":"41b7905f-a070-4ffe-abfc-67fbcd2adaa9"},"source":["## TC 5033\n","## Deep Learning\n","## Transformers\n","\n","#### Activity 4: Implementing a Translator\n","\n","- Objective\n","\n","To understand the Transformer Architecture by Implementing a translator.\n","\n","- Instructions\n","\n","    This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n","\n","    Follow the provided code. The code already implements a transformer from scratch as explained in one of [week's 9 videos](https://youtu.be/XefFj4rLHgU)\n","\n","    Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells.  You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n","  \n","- Evaluation Criteria\n","\n","    - Code Readability and Comments\n","    - Traning a translator\n","    - Translating at least 10 sentences.\n","\n","- Submission\n","\n","Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"f240f0d8-d9e0-4632-962f-1a5a7881cb5f","metadata":{"id":"f240f0d8-d9e0-4632-962f-1a5a7881cb5f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a","metadata":{"id":"5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"17f54c65","metadata":{"heading_collapsed":true,"id":"17f54c65"},"source":["#### Script to convert csv to text file"]},{"cell_type":"code","execution_count":null,"id":"8f02c0c2","metadata":{"hidden":true,"id":"8f02c0c2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731689391123,"user_tz":360,"elapsed":28842,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"3d90e118-a824-48bc-f9bc-3ac58aee7766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["#This script requires to convert the TSV file to CSV\n","# easiest way is to open it in Calc or excel and save as csv\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","PATH = '/content/drive/My Drive/Colab Notebooks/MNA/TC5033 - Deep Learning/Semana_8/english-spanish.tsv'\n","import pandas as pd\n","df = pd.read_csv(PATH, sep='\\t', on_bad_lines='skip')"]},{"cell_type":"code","execution_count":null,"id":"787d9408","metadata":{"hidden":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"787d9408","executionInfo":{"status":"ok","timestamp":1731689393271,"user_tz":360,"elapsed":2159,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"c7fe9bbe-75c5-4d0d-87ef-b012d0b030be"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-5f847c50c75d>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n"]}],"source":["eng_spa_cols = df.iloc[:, [1, 3]]\n","eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n","eng_spa_cols = eng_spa_cols.sort_values(by='length')\n","eng_spa_cols = eng_spa_cols.drop(columns=['length'])\n","\n","output_file_path = '/content/drive/My Drive/Colab Notebooks/MNA/TC5033 - Deep Learning/Semana_8/english-spanish-official.txt'\n","eng_spa_cols.to_csv(output_file_path, sep='\\t', index=False, header=False)"]},{"cell_type":"markdown","id":"7d468e9a","metadata":{"id":"7d468e9a"},"source":["## Transformer - Attention is all you need"]},{"cell_type":"code","execution_count":null,"id":"d5dcf681","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5dcf681","executionInfo":{"status":"ok","timestamp":1731689397699,"user_tz":360,"elapsed":4433,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"c83e019e-7d8b-48f2-db20-c7321554c9b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x79b854dec210>"]},"metadata":{},"execution_count":3}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from collections import Counter\n","import math\n","import numpy as np\n","import re\n","\n","torch.manual_seed(23)"]},{"cell_type":"code","execution_count":null,"id":"2c2cbd17","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c2cbd17","executionInfo":{"status":"ok","timestamp":1731689397699,"user_tz":360,"elapsed":21,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"cac3b438-a6c2-4e92-b511-9019796561bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"id":"9c6623a1","metadata":{"id":"9c6623a1"},"outputs":[],"source":["MAX_SEQ_LEN = 128"]},{"cell_type":"code","execution_count":null,"id":"3103d45f","metadata":{"code_folding":[30,94],"id":"3103d45f"},"outputs":[],"source":["class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_seq_len = MAX_SEQ_LEN):\n","        super().__init__()\n","        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n","        token_pos = torch.arange(0, max_seq_len, dtype = torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n","                             * (-math.log(10000.0)/d_model))\n","        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n","        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n","        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0,1)\n","\n","    def forward(self, x):\n","#         print(self.pos_embed_matrix.shape)\n","#         print(x.shape)\n","        return x + self.pos_embed_matrix[:x.size(0), :]\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model = 512, num_heads = 8):\n","        super().__init__()\n","        assert d_model % num_heads == 0, 'Embedding size not compatible with num heads'\n","\n","        self.d_v = d_model // num_heads\n","        self.d_k = self.d_v\n","        self.num_heads = num_heads\n","\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def forward(self, Q, K, V, mask = None):\n","        batch_size = Q.size(0)\n","        '''\n","        Q, K, V -> [batch_size, seq_len, num_heads*d_k]\n","        after transpose Q, K, V -> [batch_size, num_heads, seq_len, d_k]\n","        '''\n","        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n","        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n","        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n","\n","        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n","        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads*self.d_k)\n","        weighted_values = self.W_o(weighted_values)\n","\n","        return weighted_values, attention\n","\n","\n","    def scale_dot_product(self, Q, K, V, mask = None):\n","        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","        if mask is not None:\n","            scores = scores.masked_fill(mask == 0, -1e9)\n","        attention = F.softmax(scores, dim = -1)\n","        weighted_values = torch.matmul(attention, V)\n","\n","        return weighted_values, attention\n","\n","\n","class PositionFeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super().__init__()\n","        self.linear1 = nn.Linear(d_model, d_ff)\n","        self.linear2 = nn.Linear(d_ff, d_model)\n","\n","    def forward(self, x):\n","        return self.linear2(F.relu(self.linear1(x)))\n","\n","class EncoderSubLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout = 0.1):\n","        super().__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = PositionFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.droupout1 = nn.Dropout(dropout)\n","        self.droupout2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask = None):\n","        attention_score, _ = self.self_attn(x, x, x, mask)\n","        x = x + self.droupout1(attention_score)\n","        x = self.norm1(x)\n","        x = x + self.droupout2(self.ffn(x))\n","        return self.norm2(x)\n","\n","class Encoder(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n","        super().__init__()\n","        self.layers = nn.ModuleList([EncoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.norm = nn.LayerNorm(d_model)\n","    def forward(self, x, mask=None):\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        return self.norm(x)\n","\n","class DecoderSubLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n","        self.feed_forward = PositionFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","        self.dropout3 = nn.Dropout(dropout)\n","\n","    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n","        attention_score, _ = self.self_attn(x, x, x, target_mask)\n","        x = x + self.dropout1(attention_score)\n","        x = self.norm1(x)\n","\n","        encoder_attn, _ = self.cross_attn(x, encoder_output, encoder_output, encoder_mask)\n","        x = x + self.dropout2(encoder_attn)\n","        x = self.norm2(x)\n","\n","        ff_output = self.feed_forward(x)\n","        x = x + self.dropout3(ff_output)\n","        return self.norm3(x)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n","        super().__init__()\n","        self.layers = nn.ModuleList([DecoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.norm = nn.LayerNorm(d_model)\n","\n","    def forward(self, x, encoder_output, target_mask, encoder_mask):\n","        for layer in self.layers:\n","            x = layer(x, encoder_output, target_mask, encoder_mask)\n","        return self.norm(x)"]},{"cell_type":"code","execution_count":null,"id":"61070162","metadata":{"code_folding":[],"id":"61070162"},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, num_layers,\n","                 input_vocab_size, target_vocab_size,\n","                 max_len=MAX_SEQ_LEN, dropout=0.1):\n","        super().__init__()\n","        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n","        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n","        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n","        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n","        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n","        self.output_layer = nn.Linear(d_model, target_vocab_size)\n","\n","    def forward(self, source, target):\n","        # Encoder mask\n","        source_mask, target_mask = self.mask(source, target)\n","        # Embedding and positional Encoding\n","        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n","        source = self.pos_embedding(source)\n","        # Encoder\n","        encoder_output = self.encoder(source, source_mask)\n","\n","        # Decoder embedding and postional encoding\n","        target = self.decoder_embedding(target) * math.sqrt(self.decoder_embedding.embedding_dim)\n","        target = self.pos_embedding(target)\n","        # Decoder\n","        output = self.decoder(target, encoder_output, target_mask, source_mask)\n","\n","        return self.output_layer(output)\n","\n","\n","\n","    def mask(self, source, target):\n","        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n","        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n","        size = target.size(1)\n","        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n","        target_mask = target_mask & no_mask\n","        return source_mask, target_mask\n"]},{"cell_type":"markdown","id":"6da6b2d4","metadata":{"heading_collapsed":true,"id":"6da6b2d4"},"source":["#### Simple test"]},{"cell_type":"code","execution_count":null,"id":"d40581d6","metadata":{"hidden":true,"id":"d40581d6"},"outputs":[],"source":["seq_len_source = 10\n","seq_len_target = 10\n","batch_size = 2\n","input_vocab_size = 50\n","target_vocab_size = 50\n","\n","source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\n","target = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))"]},{"cell_type":"code","execution_count":null,"id":"fc7cf689","metadata":{"hidden":true,"id":"fc7cf689"},"outputs":[],"source":["d_model = 512\n","num_heads = 8\n","d_ff = 2048\n","num_layers = 6\n","\n","model = Transformer(d_model, num_heads, d_ff, num_layers,\n","                  input_vocab_size, target_vocab_size,\n","                  max_len=MAX_SEQ_LEN, dropout=0.1)\n","\n","model = model.to(device)\n","source = source.to(device)\n","target = target.to(device)"]},{"cell_type":"code","execution_count":null,"id":"4618560e","metadata":{"hidden":true,"id":"4618560e"},"outputs":[],"source":["output = model(source, target)"]},{"cell_type":"code","execution_count":null,"id":"ab0bc69d","metadata":{"hidden":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ab0bc69d","executionInfo":{"status":"ok","timestamp":1731689400311,"user_tz":360,"elapsed":9,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"a4f34440-1d9c-4eba-ce65-92e69cee3920"},"outputs":[{"output_type":"stream","name":"stdout","text":["ouput.shape torch.Size([2, 10, 50])\n"]}],"source":["# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\n","print(f'ouput.shape {output.shape}')"]},{"cell_type":"markdown","id":"0f4b2910","metadata":{"id":"0f4b2910"},"source":["### Translator Eng-Spa"]},{"cell_type":"code","execution_count":null,"id":"869a7244","metadata":{"id":"869a7244"},"outputs":[],"source":["PATH = '/content/drive/My Drive/Colab Notebooks/MNA/TC5033 - Deep Learning/Semana_8/english-spanish-official.txt'"]},{"cell_type":"code","execution_count":null,"id":"d0af1eba","metadata":{"id":"d0af1eba"},"outputs":[],"source":["with open(PATH, 'r', encoding='utf-8') as f:\n","    lines = f.readlines()\n","eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]"]},{"cell_type":"code","execution_count":null,"id":"c930226f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c930226f","executionInfo":{"status":"ok","timestamp":1731689401358,"user_tz":360,"elapsed":30,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"0904de0b-e0fe-41e1-cb67-907701fffef8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['Ok!', '¡OK!'],\n"," ['Go!', 'Váyase'],\n"," ['Go!', 'Vete'],\n"," ['Go!', '¡Fuera!'],\n"," ['Go!', '¡Ya!'],\n"," ['Go.', 'Váyase.'],\n"," ['Hi.', 'Hola.'],\n"," ['Ow!', '¡Ay!'],\n"," ['Go.', 'Vaya.'],\n"," ['Go!', '¡Sal!']]"]},"metadata":{},"execution_count":14}],"source":["eng_spa_pairs[:10]"]},{"cell_type":"code","execution_count":null,"id":"095f4037","metadata":{"id":"095f4037"},"outputs":[],"source":["eng_sentences = [pair[0] for pair in eng_spa_pairs]\n","spa_sentences = [pair[1] for pair in eng_spa_pairs]"]},{"cell_type":"code","execution_count":null,"id":"0d9e1c95","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d9e1c95","executionInfo":{"status":"ok","timestamp":1731689401359,"user_tz":360,"elapsed":27,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"a50351a2-41b7-4a65-dcdf-f9a8fdc2ca9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Ok!', 'Go!', 'Go!', 'Go!', 'Go!', 'Go.', 'Hi.', 'Ow!', 'Go.', 'Go!']\n","['¡OK!', 'Váyase', 'Vete', '¡Fuera!', '¡Ya!', 'Váyase.', 'Hola.', '¡Ay!', 'Vaya.', '¡Sal!']\n"]}],"source":["print(eng_sentences[:10])\n","print(spa_sentences[:10])\n"]},{"cell_type":"code","execution_count":null,"id":"60d11478","metadata":{"id":"60d11478"},"outputs":[],"source":["def preprocess_sentence(sentence):\n","    sentence = sentence.lower().strip()\n","    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n","    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n","    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n","    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n","    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n","    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n","    sentence = sentence.strip()\n","    sentence = '<sos> ' + sentence + ' <eos>'\n","    return sentence"]},{"cell_type":"code","execution_count":null,"id":"478f673b","metadata":{"id":"478f673b"},"outputs":[],"source":["s1 = '¿Hola @ cómo estás? 123'"]},{"cell_type":"code","execution_count":null,"id":"96ac79c5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96ac79c5","executionInfo":{"status":"ok","timestamp":1731689401360,"user_tz":360,"elapsed":19,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"4b9f72f4-593b-484c-ddf4-13967197ac18"},"outputs":[{"output_type":"stream","name":"stdout","text":["¿Hola @ cómo estás? 123\n","<sos> hola como estas <eos>\n"]}],"source":["print(s1)\n","print(preprocess_sentence(s1))"]},{"cell_type":"code","execution_count":null,"id":"d9fc9c4d","metadata":{"id":"d9fc9c4d"},"outputs":[],"source":["eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\n","spa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]"]},{"cell_type":"code","execution_count":null,"id":"f7a3b18d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7a3b18d","executionInfo":{"status":"ok","timestamp":1731689414083,"user_tz":360,"elapsed":14,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"d06b9284-0952-4181-dc3a-25dbfa738d18"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<sos> ok <eos>',\n"," '<sos> vayase <eos>',\n"," '<sos> vete <eos>',\n"," '<sos> fuera <eos>',\n"," '<sos> ya <eos>',\n"," '<sos> vayase <eos>',\n"," '<sos> hola <eos>',\n"," '<sos> ay <eos>',\n"," '<sos> vaya <eos>',\n"," '<sos> sal <eos>']"]},"metadata":{},"execution_count":21}],"source":["spa_sentences[:10]"]},{"cell_type":"code","execution_count":null,"id":"97931cd3","metadata":{"id":"97931cd3"},"outputs":[],"source":["def build_vocab(sentences):\n","    words = [word for sentence in sentences for word in sentence.split()]\n","    word_count = Counter(words)\n","    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n","    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n","    word2idx['<pad>'] = 0\n","    word2idx['<unk>'] = 1\n","    idx2word = {idx: word for word, idx in word2idx.items()}\n","    return word2idx, idx2word"]},{"cell_type":"code","execution_count":null,"id":"7fa8738e","metadata":{"id":"7fa8738e"},"outputs":[],"source":["eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\n","spa_word2idx, spa_idx2word = build_vocab(spa_sentences)\n","eng_vocab_size = len(eng_word2idx)\n","spa_vocab_size = len(spa_word2idx)"]},{"cell_type":"code","execution_count":null,"id":"79d6b633","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79d6b633","executionInfo":{"status":"ok","timestamp":1731689416082,"user_tz":360,"elapsed":13,"user":{"displayName":"Moises flores ortiz","userId":"12511678252167501645"}},"outputId":"f168fe5c-fec2-482f-8382-ccac6bae21ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["27653 46933\n"]}],"source":["print(eng_vocab_size, spa_vocab_size)"]},{"cell_type":"code","execution_count":null,"id":"e564017c","metadata":{"id":"e564017c"},"outputs":[],"source":["class EngSpaDataset(Dataset):\n","    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n","        self.eng_sentences = eng_sentences\n","        self.spa_sentences = spa_sentences\n","        self.eng_word2idx = eng_word2idx\n","        self.spa_word2idx = spa_word2idx\n","\n","    def __len__(self):\n","        return len(self.eng_sentences)\n","\n","    def __getitem__(self, idx):\n","        eng_sentence = self.eng_sentences[idx]\n","        spa_sentence = self.spa_sentences[idx]\n","        # return tokens idxs\n","        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n","        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n","\n","        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)"]},{"cell_type":"code","execution_count":null,"id":"b579577b","metadata":{"id":"b579577b"},"outputs":[],"source":["def collate_fn(batch):\n","    eng_batch, spa_batch = zip(*batch)\n","    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n","    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n","    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n","    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n","    return eng_batch, spa_batch\n"]},{"cell_type":"code","execution_count":null,"id":"8d514b7c","metadata":{"id":"8d514b7c"},"outputs":[],"source":["def train(model, dataloader, loss_function, optimiser, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n","            eng_batch = eng_batch.to(device)\n","            spa_batch = spa_batch.to(device)\n","            # Decoder preprocessing\n","            target_input = spa_batch[:, :-1]\n","            target_output = spa_batch[:, 1:].contiguous().view(-1)\n","            # Zero grads\n","            optimiser.zero_grad()\n","            # run model\n","            output = model(eng_batch, target_input)\n","            output = output.view(-1, output.size(-1))\n","            # loss\\\n","            loss = loss_function(output, target_output)\n","            # gradient and update parameters\n","            loss.backward()\n","            optimiser.step()\n","            total_loss += loss.item()\n","\n","        avg_loss = total_loss/len(dataloader)\n","        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')\n","\n"]},{"cell_type":"code","execution_count":null,"id":"2379ea72","metadata":{"id":"2379ea72"},"outputs":[],"source":["BATCH_SIZE = 64\n","dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)\n","dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"id":"e08eef6a","metadata":{"id":"e08eef6a"},"outputs":[],"source":["model = Transformer(d_model=512, num_heads=8, d_ff=2048, num_layers=6,\n","                    input_vocab_size=eng_vocab_size, target_vocab_size=spa_vocab_size,\n","                    max_len=MAX_SEQ_LEN, dropout=0.1)"]},{"cell_type":"code","execution_count":null,"id":"a1181a12","metadata":{"id":"a1181a12"},"outputs":[],"source":["model = model.to(device)\n","loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","optimiser = optim.Adam(model.parameters(), lr=0.0001)\n"]},{"cell_type":"code","execution_count":null,"id":"14e265e9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14e265e9","outputId":"1d799a78-1d2c-48bb-e14b-75505a0ea976"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0/10, Loss: 3.6018\n","Epoch: 1/10, Loss: 2.2037\n","Epoch: 2/10, Loss: 1.7052\n","Epoch: 3/10, Loss: 1.3767\n","Epoch: 4/10, Loss: 1.1263\n"]}],"source":["train(model, dataloader, loss_function, optimiser, epochs = 10)"]},{"cell_type":"code","execution_count":null,"id":"1d271146","metadata":{"id":"1d271146"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"50740746","metadata":{"code_folding":[],"id":"50740746"},"outputs":[],"source":["def sentence_to_indices(sentence, word2idx):\n","    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n","\n","def indices_to_sentence(indices, idx2word):\n","    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])\n","\n","def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n","    model.eval()\n","    sentence = preprocess_sentence(sentence)\n","    input_indices = sentence_to_indices(sentence, eng_word2idx)\n","    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n","\n","    # Initialize the target tensor with <sos> token\n","    tgt_indices = [spa_word2idx['<sos>']]\n","    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        for _ in range(max_len):\n","            output = model(input_tensor, tgt_tensor)\n","            output = output.squeeze(0)\n","            next_token = output.argmax(dim=-1)[-1].item()\n","            tgt_indices.append(next_token)\n","            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n","            if next_token == spa_word2idx['<eos>']:\n","                break\n","\n","    return indices_to_sentence(tgt_indices, spa_idx2word)"]},{"cell_type":"code","execution_count":null,"id":"c2c0db72","metadata":{"code_folding":[15],"id":"c2c0db72"},"outputs":[],"source":["def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n","    for sentence in sentences:\n","        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n","        print(f'Input sentence: {sentence}')\n","        print(f'Traducción: {translation}')\n","        print()\n","\n","# Example sentences to test the translator\n","test_sentences = [\n","    \"Hello, how are you?\",\n","    \"I am learning artificial intelligence.\",\n","    \"Artificial intelligence is great.\",\n","    \"Good night!\"\n","]\n","\n","# Assuming the model is trained and loaded\n","# Set the device to 'cpu' or 'cuda' as needed\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Evaluate translations\n","evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)\n"]},{"cell_type":"code","execution_count":null,"id":"4ceefe95","metadata":{"id":"4ceefe95"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a7e10a50","metadata":{"id":"a7e10a50"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"bffb7af9","metadata":{"id":"bffb7af9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6321db74","metadata":{"id":"6321db74"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ccce7864","metadata":{"id":"ccce7864"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}